{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'cfg_decoding.logits_processor' from '/workspaces/funcqa_experiments/cfg_decoding/logits_processor.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import LogitsProcessor, AutoModelForCausalLM, AutoTokenizer, BeamSearchScorer, LogitsProcessorList, MaxLengthCriteria, StoppingCriteriaList\n",
    "\n",
    "import cfg_decoding.parsing as p\n",
    "import cfg_decoding.logits_processor as lp\n",
    "\n",
    "import importlib\n",
    "importlib.reload(p)\n",
    "importlib.reload(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-13b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State(start_idx=0, terminals={'__ANON_0'})\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(p)\n",
    "\n",
    "with open(\"funcqa.lark\", \"r\") as f:\n",
    "    cfg_def = f.read()\n",
    "\n",
    "stepper = p.create_parsing_stepper(cfg_def, tokenizer)\n",
    "\n",
    "print(stepper.get_parsing_state(\"add(1\"))\n",
    "\n",
    "# s = 'add(10., 2.)'\n",
    "# for i in range(len(s)+1):\n",
    "#     cfg_state = stepper.get_parsing_state(s[:i])\n",
    "#     print(f\"'{s[:i]}' -> {cfg_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, load_in_4bit=True, device_map=\"cuda:1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n",
      "2023-11-24 12:19:19.130368: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-24 12:19:19.130397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-24 12:19:19.131241: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-24 12:19:19.135342: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 12:19:19.773753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequences:  ['', '']\n",
      "Parsing states:  [State(start_idx=0, terminals={'__ANON_0'}), State(start_idx=0, terminals={'__ANON_0'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [['<'], ['<']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<', '<']\n",
      "Parsing states:  [State(start_idx=0, terminals={'__ANON_0'}), State(start_idx=0, terminals={'__ANON_0'})]\n",
      "Existing tokens for terminal:  ['<', '<']\n",
      "Valid tokens:  [['T'], ['T']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T', '<T']\n",
      "Parsing states:  [State(start_idx=0, terminals={'__ANON_0'}), State(start_idx=0, terminals={'__ANON_0'})]\n",
      "Existing tokens for terminal:  ['<T', '<T']\n",
      "Valid tokens:  [['>'], ['>']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T>', '<T>']\n",
      "Parsing states:  [State(start_idx=3, terminals={'SUBTRACT', 'DIVIDE', 'ADD', 'MULTIPLY'}), State(start_idx=3, terminals={'SUBTRACT', 'DIVIDE', 'ADD', 'MULTIPLY'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [['ad', 'add', 'sub', 'su', 'mu', 'div', 'mult', 'di', 'multi', 'mul', 'multip', 'a', 's', 'd', 'm'], ['ad', 'add', 'sub', 'su', 'mu', 'div', 'mult', 'di', 'multi', 'mul', 'multip', 'a', 's', 'd', 'm']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T>add', '<T>mul']\n",
      "Parsing states:  [State(start_idx=6, terminals={'LPAR'}), State(start_idx=3, terminals={'SUBTRACT', 'DIVIDE', 'ADD', 'MULTIPLY'})]\n",
      "Existing tokens for terminal:  ['', 'mul']\n",
      "Valid tokens:  [['('], ['ti', 'tip', 't']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T>add(', '<T>multip']\n",
      "Parsing states:  [State(start_idx=7, terminals={'INT'}), State(start_idx=3, terminals={'SUBTRACT', 'DIVIDE', 'ADD', 'MULTIPLY'})]\n",
      "Existing tokens for terminal:  ['', 'multip']\n",
      "Valid tokens:  [['1', '0', '2', '9', '3', '5', '4', '8', '6', '7'], ['ly', 'l']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T>add(1', '<T>add(2']\n",
      "Parsing states:  [State(start_idx=8, terminals={'COMMA', 'INT'}), State(start_idx=8, terminals={'COMMA', 'INT'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[',', '1', '0', '2', '9', '3', '5', '4', '8', '6', '7'], [',', '1', '0', '2', '9', '3', '5', '4', '8', '6', '7']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T>add(1,', '<T>add(2,']\n",
      "Parsing states:  [State(start_idx=9, terminals={'INT'}), State(start_idx=9, terminals={'INT'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [['1', '0', '2', '9', '3', '5', '4', '8', '6', '7'], ['1', '0', '2', '9', '3', '5', '4', '8', '6', '7']]\n",
      "--------------------\n",
      "Decoded sequences:  ['<T>add(1,2', '<T>add(1,1']\n",
      "Parsing states:  [State(start_idx=10, terminals={'INT', 'RPAR'}), State(start_idx=10, terminals={'INT', 'RPAR'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [['1', ')', '0', '2', '9', '3', '5', '4', '8', '6', '7'], ['1', ')', '0', '2', '9', '3', '5', '4', '8', '6', '7']]\n",
      "--------------------\n",
      "Decoded sequences:  ['T>add(1,20', 'T>add(1,10']\n",
      "Parsing states:  [State(start_idx=11, terminals={'INT', 'RPAR'}), State(start_idx=11, terminals={'INT', 'RPAR'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [['1', ')', '0', '2', '9', '3', '5', '4', '8', '6', '7'], ['1', ')', '0', '2', '9', '3', '5', '4', '8', '6', '7']]\n",
      "--------------------\n",
      "Decoded sequences:  ['>add(1,20)', '>add(1,10)']\n",
      "Parsing states:  [State(start_idx=12, terminals={'__ANON_1'}), State(start_idx=12, terminals={'__ANON_1'})]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [['</', '<'], ['</', '<']]\n",
      "--------------------\n",
      "Decoded sequences:  ['dd(1,20)</', 'dd(1,10)</']\n",
      "Parsing states:  [State(start_idx=12, terminals={'__ANON_1'}), State(start_idx=12, terminals={'__ANON_1'})]\n",
      "Existing tokens for terminal:  ['</', '</']\n",
      "Valid tokens:  [['T'], ['T']]\n",
      "--------------------\n",
      "Decoded sequences:  ['d(1,20)</T', 'd(1,10)</T']\n",
      "Parsing states:  [State(start_idx=12, terminals={'__ANON_1'}), State(start_idx=12, terminals={'__ANON_1'})]\n",
      "Existing tokens for terminal:  ['</T', '</T']\n",
      "Valid tokens:  [['>'], ['>']]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,10)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,20)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,20)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,20)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,20)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,20)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Decoded sequences:  ['(1,20)</T>', '(1,20)</T>']\n",
      "Parsing states:  [State(start_idx=16, terminals=[]), State(start_idx=16, terminals=[])]\n",
      "Existing tokens for terminal:  ['', '']\n",
      "Valid tokens:  [[], []]\n",
      "--------------------\n",
      "Use functions add, mul, div and sub to solve the following math problem.\n",
      "\n",
      "E.g. multiply(1, 20) or add(1, mul(2, 3)) or divide(5, 3) or subtract(15, 3) or add(10, 2)\n",
      "\n",
      "Question: 1 + 20\n",
      "\n",
      "Calculation: <T>add(1,20)</T>\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(lp)\n",
    "\n",
    "num_beams = 2\n",
    "input_prompt = '''Use functions add, mul, div and sub to solve the following math problem.\n",
    "\n",
    "E.g. multiply(1, 20) or add(1, mul(2, 3)) or divide(5, 3) or subtract(15, 3) or add(10, 2)\n",
    "\n",
    "Question: 1 + 20\n",
    "\n",
    "Calculation: '''\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    input_prompt, \n",
    "    return_tensors=\"pt\"\n",
    ").input_ids\n",
    "input_ids = torch.stack([input_ids] * num_beams, dim=0).reshape(num_beams, -1).to(model.device)\n",
    "bos_ids = torch.ones((num_beams, 1), device=model.device, dtype=torch.long) * model.config.bos_token_id\n",
    "input_ids = torch.cat([bos_ids, input_ids], dim=-1)\n",
    "\n",
    "prompt_end_index = input_ids.shape[1]\n",
    "max_length = prompt_end_index + 20\n",
    "\n",
    "final_sentence = model.beam_search(\n",
    "    input_ids, \n",
    "    beam_scorer=BeamSearchScorer(\n",
    "        batch_size=1,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "        device=\"cuda\",\n",
    "        length_penalty=1.0,\n",
    "        do_early_stopping=True,\n",
    "    ),\n",
    "    logits_processor = LogitsProcessorList([\n",
    "        lp.GrammarConstrainedLogitsProcessor(tokenizer, stepper, prompt_end_index=prompt_end_index)\n",
    "    ]),\n",
    "    stopping_criteria = StoppingCriteriaList([\n",
    "        MaxLengthCriteria(max_length=max_length)\n",
    "    ]),\n",
    "    pad_token_id=tokenizer.eos_token_id, \n",
    ")\n",
    "\n",
    "final_sentence_str = tokenizer.batch_decode(final_sentence, skip_special_tokens=True)[0]\n",
    "print(final_sentence_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
